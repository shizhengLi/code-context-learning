# Code Contextæ€§èƒ½ä¼˜åŒ–å’Œæ‰©å±•æ€§åˆ†æ

## æ¦‚è¿°

Code Contexté¡¹ç›®åœ¨è®¾è®¡æ—¶å……åˆ†è€ƒè™‘äº†å¤§è§„æ¨¡ä»£ç åº“çš„å¤„ç†éœ€æ±‚å’Œæ€§èƒ½ä¼˜åŒ–ã€‚æœ¬æ–‡æ¡£æ·±å…¥åˆ†æç³»ç»Ÿåœ¨æ‰¹é‡å¤„ç†ã€å†…å­˜ç®¡ç†ã€å¹¶å‘æ§åˆ¶ã€èµ„æºä¼˜åŒ–ç­‰æ–¹é¢çš„å®ç°ç­–ç•¥ï¼Œä»¥åŠå…¶åœ¨å¤„ç†å¤§è§„æ¨¡ä»£ç åº“æ—¶çš„æ‰©å±•æ€§è¡¨ç°ã€‚

## 1. æ‰¹é‡å¤„ç†æ¶æ„

### 1.1 åˆ†å—å¤„ç†ç­–ç•¥

#### æ‰¹é‡å¤§å°é…ç½®
```typescript
private async processFileList(
    filePaths: string[],
    codebasePath: string,
    onFileProcessed?: (filePath: string, fileIndex: number, totalFiles: number) => void
): Promise<{ processedFiles: number; totalChunks: number; status: 'completed' | 'limit_reached' }> {
    // æ‰¹é‡å¤„ç†é…ç½®
    const EMBEDDING_BATCH_SIZE = Math.max(1, parseInt(envManager.get('EMBEDDING_BATCH_SIZE') || '100', 10));
    const CHUNK_LIMIT = 450000;
    console.log(`ğŸ”§ Using EMBEDDING_BATCH_SIZE: ${EMBEDDING_BATCH_SIZE}`);
    
    let chunkBuffer: Array<{ chunk: CodeChunk; codebasePath: string }> = [];
    let processedFiles = 0;
    let totalChunks = 0;
    let limitReached = false;
    
    for (let i = 0; i < filePaths.length; i++) {
        const filePath = filePaths[i];
        
        try {
            const content = await fs.promises.readFile(filePath, 'utf-8');
            const language = this.getLanguageFromExtension(path.extname(filePath));
            const chunks = await this.codeSplitter.split(content, language, filePath);
            
            // å°†chunksæ·»åŠ åˆ°ç¼“å†²åŒº
            for (const chunk of chunks) {
                chunkBuffer.push({ chunk, codebasePath });
                totalChunks++;
                
                // å½“ç¼“å†²åŒºè¾¾åˆ°EMBEDDING_BATCH_SIZEæ—¶å¤„ç†æ‰¹æ¬¡
                if (chunkBuffer.length >= EMBEDDING_BATCH_SIZE) {
                    try {
                        await this.processChunkBuffer(chunkBuffer);
                    } catch (error) {
                        console.error(`âŒ Failed to process chunk batch: ${error}`);
                    } finally {
                        chunkBuffer = []; // æ€»æ˜¯æ¸…ç©ºç¼“å†²åŒºï¼Œå³ä½¿å¤±è´¥
                    }
                }
                
                // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°chunké™åˆ¶
                if (totalChunks >= CHUNK_LIMIT) {
                    console.warn(`âš ï¸  Chunk limit of ${CHUNK_LIMIT} reached. Stopping indexing.`);
                    limitReached = true;
                    break;
                }
            }
            
            processedFiles++;
            onFileProcessed?.(filePath, i + 1, filePaths.length);
            
            if (limitReached) {
                break;
            }
        } catch (error) {
            console.error(`âŒ Failed to process file ${filePath}:`, error);
        }
    }
    
    // å¤„ç†å‰©ä½™çš„chunks
    if (chunkBuffer.length > 0) {
        try {
            await this.processChunkBuffer(chunkBuffer);
        } catch (error) {
            console.error(`âŒ Failed to process final chunk batch: ${error}`);
        }
    }
    
    return {
        processedFiles,
        totalChunks,
        status: limitReached ? 'limit_reached' : 'completed'
    };
}
```

#### ç¼“å†²åŒºç®¡ç†
```typescript
/**
 * å¤„ç†ç´¯ç§¯çš„chunkç¼“å†²åŒº
 */
private async processChunkBuffer(chunkBuffer: Array<{ chunk: CodeChunk; codebasePath: string }>): Promise<void> {
    if (chunkBuffer.length === 0) return;
    
    // æå–chunkså¹¶ç¡®ä¿å®ƒä»¬éƒ½æœ‰ç›¸åŒçš„codebasePath
    const chunks = chunkBuffer.map(item => item.chunk);
    const codebasePath = chunkBuffer[0].codebasePath;
    
    // ä¼°ç®—tokenæ•°ï¼ˆç²—ç•¥ä¼°ç®—ï¼š1 token â‰ˆ 4ä¸ªå­—ç¬¦ï¼‰
    const estimatedTokens = chunks.reduce((sum, chunk) => sum + Math.ceil(chunk.content.length / 4), 0);
    console.log(`ğŸ”„ Processing batch of ${chunks.length} chunks (~${estimatedTokens} tokens)`);
    
    await this.processChunkBatch(chunks, codebasePath);
}
```

### 1.2 æ‰¹é‡å‘é‡åŒ–

#### æŠ½è±¡æ‰¹é‡æ¥å£
```typescript
abstract class BaseEmbedding {
    abstract embedBatch(texts: string[]): Promise<EmbeddingVector[]>;
    abstract getDimension(): number;
    abstract getProvider(): string;
}
```

#### OpenAIæ‰¹é‡å®ç°
```typescript
async embedBatch(texts: string[]): Promise<EmbeddingVector[]> {
    const processedTexts = this.preprocessTexts(texts);
    const model = this.config.model || 'text-embedding-3-small';
    
    const response = await this.client.embeddings.create({
        model: model,
        input: processedTexts,
        encoding_format: 'float',
    });
    
    return response.data.map((item) => ({
        vector: item.embedding,
        dimension: this.dimension
    }));
}
```

### 1.3 æ‰¹é‡æ•°æ®åº“æ’å…¥

#### æ‰¹é‡æ’å…¥ç­–ç•¥
```typescript
private async processChunkBatch(chunks: CodeChunk[], codebasePath: string): Promise<void> {
    // ç”ŸæˆåµŒå…¥å‘é‡
    const chunkContents = chunks.map(chunk => chunk.content);
    const embeddings: EmbeddingVector[] = await this.embedding.embedBatch(chunkContents);
    
    // å‡†å¤‡å‘é‡æ–‡æ¡£
    const documents: VectorDocument[] = chunks.map((chunk, index) => ({
        id: this.generateChunkId(chunk, codebasePath),
        vector: embeddings[index].vector,
        content: chunk.content,
        relativePath: path.relative(codebasePath, chunk.metadata.filePath || ''),
        startLine: chunk.metadata.startLine,
        endLine: chunk.metadata.endLine,
        fileExtension: path.extname(chunk.metadata.filePath || ''),
        metadata: {
            language: chunk.metadata.language,
            filePath: chunk.metadata.filePath,
            ...chunk.metadata
        }
    }));
    
    // æ‰¹é‡æ’å…¥å‘é‡æ•°æ®åº“
    await this.vectorDatabase.insert(this.getCollectionName(codebasePath), documents);
    
    console.log(`âœ… Successfully processed batch of ${documents.length} chunks`);
}
```

## 2. å†…å­˜ç®¡ç†ä¼˜åŒ–

### 2.1 æµå¼å¤„ç†

#### å†…å­˜æ§åˆ¶ç­–ç•¥
```typescript
class MemoryManager {
    private maxMemoryUsage: number = 1024 * 1024 * 1024; // 1GB
    private currentUsage: number = 0;
    
    checkMemoryAvailability(): boolean {
        const usage = process.memoryUsage();
        this.currentUsage = usage.heapUsed;
        
        if (this.currentUsage > this.maxMemoryUsage) {
            console.warn(`âš ï¸  Memory usage high: ${this.formatBytes(this.currentUsage)}`);
            return false;
        }
        
        return true;
    }
    
    private formatBytes(bytes: number): string {
        const sizes = ['Bytes', 'KB', 'MB', 'GB'];
        if (bytes === 0) return '0 Bytes';
        const i = Math.floor(Math.log(bytes) / Math.log(1024));
        return Math.round(bytes / Math.pow(1024, i) * 100) / 100 + ' ' + sizes[i];
    }
}
```

#### åˆ†æ‰¹è¯»å–å¤§æ–‡ä»¶
```typescript
async processLargeFile(filePath: string, chunkSize: number = 1024 * 1024): Promise<void> {
    const fileHandle = await fs.promises.open(filePath, 'r');
    const stats = await fileHandle.stat();
    const fileSize = stats.size;
    
    let position = 0;
    let buffer = '';
    
    while (position < fileSize) {
        const { bytesRead } = await fileHandle.read({
            buffer: Buffer.alloc(chunkSize),
            position
        });
        
        if (bytesRead === 0) break;
        
        buffer += buffer.toString('utf-8', 0, bytesRead);
        position += bytesRead;
        
        // å¤„ç†ç¼“å†²åŒºä¸­çš„å®Œæ•´ä»£ç å—
        const lines = buffer.split('\n');
        buffer = lines.pop() || ''; // ä¿ç•™ä¸å®Œæ•´çš„è¡Œ
        
        await this.processCodeLines(lines);
        
        // å†…å­˜æ£€æŸ¥
        if (!this.memoryManager.checkMemoryAvailability()) {
            await this.gc();
        }
    }
    
    await fileHandle.close();
}
```

### 2.2 åƒåœ¾å›æ”¶æ§åˆ¶

#### ä¸»åŠ¨åƒåœ¾å›æ”¶
```typescript
class GcManager {
    private gcThreshold: number = 100 * 1024 * 1024; // 100MB
    private lastGcTime: number = 0;
    private gcInterval: number = 5000; // 5ç§’
    
    async conditionalGc(): Promise<void> {
        const now = Date.now();
        const usage = process.memoryUsage();
        
        if (usage.heapUsed > this.gcThreshold && 
            now - this.lastGcTime > this.gcInterval) {
            
            console.log('ğŸ—‘ï¸  Running garbage collection...');
            
            if (global.gc) {
                global.gc();
                this.lastGcTime = now;
                
                const afterUsage = process.memoryUsage();
                console.log(`âœ… GC completed. Freed: ${this.formatBytes(usage.heapUsed - afterUsage.heapUsed)}`);
            } else {
                console.warn('âš ï¸  Global GC not available');
            }
        }
    }
    
    private formatBytes(bytes: number): string {
        const sizes = ['Bytes', 'KB', 'MB', 'GB'];
        if (bytes === 0) return '0 Bytes';
        const i = Math.floor(Math.log(bytes) / Math.log(1024));
        return Math.round(bytes / Math.pow(1024, i) * 100) / 100 + ' ' + sizes[i];
    }
}
```

## 3. å¹¶å‘æ§åˆ¶

### 3.1 å¹¶å‘é™åˆ¶å™¨

#### ä¿¡å·é‡å®ç°
```typescript
class Semaphore {
    private permits: number;
    private queue: Array<{ resolve: Function; reject: Function }> = [];
    
    constructor(permits: number) {
        this.permits = permits;
    }
    
    async acquire(): Promise<void> {
        if (this.permits > 0) {
            this.permits--;
            return Promise.resolve();
        }
        
        return new Promise((resolve, reject) => {
            this.queue.push({ resolve, reject });
        });
    }
    
    release(): void {
        this.permits++;
        
        if (this.queue.length > 0) {
            const { resolve } = this.queue.shift()!;
            resolve();
            this.permits--;
        }
    }
}

class ConcurrencyManager {
    private embeddingSemaphore: Semaphore;
    private databaseSemaphore: Semaphore;
    
    constructor(maxConcurrentEmbeddings: number = 5, maxConcurrentDbOps: number = 10) {
        this.embeddingSemaphore = new Semaphore(maxConcurrentEmbeddings);
        this.databaseSemaphore = new Semaphore(maxConcurrentDbOps);
    }
    
    async withEmbeddingLimit<T>(operation: () => Promise<T>): Promise<T> {
        await this.embeddingSemaphore.acquire();
        try {
            return await operation();
        } finally {
            this.embeddingSemaphore.release();
        }
    }
    
    async withDatabaseLimit<T>(operation: () => Promise<T>): Promise<T> {
        await this.databaseSemaphore.acquire();
        try {
            return await operation();
        } finally {
            this.databaseSemaphore.release();
        }
    }
}
```

### 3.2 ä»»åŠ¡é˜Ÿåˆ—

#### å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—
```typescript
class TaskQueue {
    private queue: Array<{ task: Function; resolve: Function; reject: Function }> = [];
    private running: boolean = false;
    private concurrency: number;
    private activeTasks: number = 0;
    
    constructor(concurrency: number = 3) {
        this.concurrency = concurrency;
    }
    
    async add<T>(task: () => Promise<T>): Promise<T> {
        return new Promise((resolve, reject) => {
            this.queue.push({ task, resolve, reject });
            this.process();
        });
    }
    
    private async process(): Promise<void> {
        if (this.running || this.activeTasks >= this.concurrency) return;
        
        this.running = true;
        
        while (this.queue.length > 0 && this.activeTasks < this.concurrency) {
            const { task, resolve, reject } = this.queue.shift()!;
            this.activeTasks++;
            
            this.executeTask(task, resolve, reject);
        }
        
        this.running = false;
    }
    
    private async executeTask(task: Function, resolve: Function, reject: Function): Promise<void> {
        try {
            const result = await task();
            resolve(result);
        } catch (error) {
            reject(error);
        } finally {
            this.activeTasks--;
            this.process();
        }
    }
}
```

## 4. èµ„æºä¼˜åŒ–ç­–ç•¥

### 4.1 è¿æ¥æ± ç®¡ç†

#### HTTPè¿æ¥æ± 
```typescript
class ConnectionPool {
    private pool: Map<string, Agent> = new Map();
    private maxSockets: number = 50;
    private maxFreeSockets: number = 10;
    private keepAlive: boolean = true;
    private keepAliveMsecs: number = 30000;
    
    getAgent(baseUrl: string): Agent {
        if (!this.pool.has(baseUrl)) {
            const agent = new http.Agent({
                maxSockets: this.maxSockets,
                maxFreeSockets: this.maxFreeSockets,
                keepAlive: this.keepAlive,
                keepAliveMsecs: this.keepAliveMsecs
            });
            
            this.pool.set(baseUrl, agent);
        }
        
        return this.pool.get(baseUrl)!;
    }
    
    closeAll(): void {
        for (const [baseUrl, agent] of this.pool) {
            agent.destroy();
        }
        this.pool.clear();
    }
}
```

#### æ•°æ®åº“è¿æ¥ç®¡ç†
```typescript
class DatabaseConnectionManager {
    private connections: Map<string, any> = new Map();
    private maxConnections: number = 20;
    private connectionTimeout: number = 30000;
    
    async getConnection(config: DatabaseConfig): Promise<any> {
        const key = this.getConnectionKey(config);
        
        if (this.connections.has(key)) {
            return this.connections.get(key);
        }
        
        if (this.connections.size >= this.maxConnections) {
            throw new Error('Maximum database connections reached');
        }
        
        const connection = await this.createConnection(config);
        this.connections.set(key, connection);
        
        return connection;
    }
    
    private getConnectionKey(config: DatabaseConfig): string {
        return `${config.host}:${config.port}:${config.database}`;
    }
    
    async closeAll(): Promise<void> {
        const closePromises = Array.from(this.connections.values()).map(
            connection => connection.close()
        );
        
        await Promise.all(closePromises);
        this.connections.clear();
    }
}
```

### 4.2 ç¼“å­˜ç­–ç•¥

#### å¤šçº§ç¼“å­˜
```typescript
class MultiLevelCache {
    private l1Cache: Map<string, { value: any; ttl: number }> = new Map(); // å†…å­˜ç¼“å­˜
    private l2Cache: Map<string, { value: any; ttl: number }> = new Map(); // æŒä¹…åŒ–ç¼“å­˜
    private l1MaxSize: number = 1000;
    private l2MaxSize: number = 10000;
    
    async get(key: string): Promise<any | null> {
        // L1ç¼“å­˜æŸ¥æ‰¾
        const l1Item = this.l1Cache.get(key);
        if (l1Item && Date.now() < l1Item.ttl) {
            return l1Item.value;
        }
        
        // L2ç¼“å­˜æŸ¥æ‰¾
        const l2Item = this.l2Cache.get(key);
        if (l2Item && Date.now() < l2Item.ttl) {
            // æå‡åˆ°L1ç¼“å­˜
            this.setL1(key, l2Item.value, l2Item.ttl);
            return l2Item.value;
        }
        
        return null;
    }
    
    async set(key: string, value: any, ttlMs: number): Promise<void> {
        const ttl = Date.now() + ttlMs;
        
        this.setL1(key, value, ttl);
        this.setL2(key, value, ttl);
    }
    
    private setL1(key: string, value: any, ttl: number): void {
        if (this.l1Cache.size >= this.l1MaxSize) {
            // åˆ é™¤æœ€æ—§çš„æ¡ç›®
            const oldestKey = this.l1Cache.keys().next().value;
            this.l1Cache.delete(oldestKey);
        }
        
        this.l1Cache.set(key, { value, ttl });
    }
    
    private setL2(key: string, value: any, ttl: number): void {
        if (this.l2Cache.size >= this.l2MaxSize) {
            // åˆ é™¤æœ€æ—§çš„æ¡ç›®
            const oldestKey = this.l2Cache.keys().next().value;
            this.l2Cache.delete(oldestKey);
        }
        
        this.l2Cache.set(key, { value, ttl });
    }
}
```

## 5. å¤§è§„æ¨¡ä»£ç åº“å¤„ç†

### 5.1 å¢é‡ç´¢å¼•

#### åŸºäºæ–‡ä»¶å“ˆå¸Œçš„å¢é‡å¤„ç†
```typescript
class IncrementalIndexer {
    private fileHashCache: Map<string, string> = new Map();
    private hashCachePath: string;
    
    constructor(cachePath: string) {
        this.hashCachePath = cachePath;
        this.loadHashCache();
    }
    
    async getChangedFiles(directory: string): Promise<string[]> {
        const allFiles = await this.getAllCodeFiles(directory);
        const changedFiles: string[] = [];
        
        for (const filePath of allFiles) {
            const currentHash = await this.calculateFileHash(filePath);
            const cachedHash = this.fileHashCache.get(filePath);
            
            if (currentHash !== cachedHash) {
                changedFiles.push(filePath);
                this.fileHashCache.set(filePath, currentHash);
            }
        }
        
        this.saveHashCache();
        return changedFiles;
    }
    
    private async calculateFileHash(filePath: string): Promise<string> {
        const content = await fs.promises.readFile(filePath, 'utf-8');
        return crypto.createHash('md5').update(content).digest('hex');
    }
    
    private loadHashCache(): void {
        try {
            if (fs.existsSync(this.hashCachePath)) {
                const data = fs.readFileSync(this.hashCachePath, 'utf-8');
                const cache = JSON.parse(data);
                this.fileHashCache = new Map(Object.entries(cache));
            }
        } catch (error) {
            console.warn('Failed to load hash cache:', error);
        }
    }
    
    private saveHashCache(): void {
        try {
            const cache = Object.fromEntries(this.fileHashCache);
            fs.writeFileSync(this.hashCachePath, JSON.stringify(cache, null, 2));
        } catch (error) {
            console.error('Failed to save hash cache:', error);
        }
    }
}
```

### 5.2 åˆ†å¸ƒå¼å¤„ç†

#### å·¥ä½œèŠ‚ç‚¹åˆ†é…
```typescript
class DistributedProcessor {
    private nodes: WorkerNode[] = [];
    private loadBalancer: LoadBalancer;
    
    constructor(nodeConfigs: WorkerNodeConfig[]) {
        this.nodes = nodeConfigs.map(config => new WorkerNode(config));
        this.loadBalancer = new LoadBalancer(this.nodes);
    }
    
    async distributeFiles(filePaths: string[]): Promise<ProcessingResult[]> {
        const batches = this.createBatches(filePaths);
        const results: ProcessingResult[] = [];
        
        const promises = batches.map(async (batch, index) => {
            const node = await this.loadBalancer.getNode();
            
            try {
                const result = await node.processBatch(batch);
                this.loadBalancer.releaseNode(node, true);
                return result;
            } catch (error) {
                this.loadBalancer.releaseNode(node, false);
                throw error;
            }
        });
        
        const batchResults = await Promise.allSettled(promises);
        
        batchResults.forEach((result, index) => {
            if (result.status === 'fulfilled') {
                results.push(result.value);
            } else {
                console.error(`Batch ${index} failed:`, result.reason);
                results.push({
                    batchId: index,
                    success: false,
                    error: result.reason.message
                });
            }
        });
        
        return results;
    }
    
    private createBatches(filePaths: string[]): string[][] {
        const batchSize = 100; // æ¯æ‰¹100ä¸ªæ–‡ä»¶
        const batches: string[][] = [];
        
        for (let i = 0; i < filePaths.length; i += batchSize) {
            batches.push(filePaths.slice(i, i + batchSize));
        }
        
        return batches;
    }
}
```

### 5.3 å®¹é”™å’Œé‡è¯•

#### æŒ‡æ•°é€€é¿é‡è¯•
```typescript
class RetryManager {
    private maxRetries: number = 3;
    private baseDelay: number = 1000;
    private maxDelay: number = 30000;
    
    async withRetry<T>(
        operation: () => Promise<T>,
        context: string
    ): Promise<T> {
        let lastError: Error;
        
        for (let attempt = 1; attempt <= this.maxRetries; attempt++) {
            try {
                return await operation();
            } catch (error) {
                lastError = error as Error;
                
                if (attempt === this.maxRetries) {
                    break;
                }
                
                const delay = this.calculateDelay(attempt);
                console.warn(`[${context}] Attempt ${attempt} failed, retrying in ${delay}ms:`, error.message);
                
                await this.sleep(delay);
            }
        }
        
        throw new Error(`[${context}] Failed after ${this.maxRetries} attempts: ${lastError?.message}`);
    }
    
    private calculateDelay(attempt: number): number {
        const delay = this.baseDelay * Math.pow(2, attempt - 1);
        return Math.min(delay, this.maxDelay);
    }
    
    private sleep(ms: number): Promise<void> {
        return new Promise(resolve => setTimeout(resolve, ms));
    }
}
```

## 6. æ€§èƒ½ç›‘æ§

### 6.1 æŒ‡æ ‡æ”¶é›†

#### æ€§èƒ½æŒ‡æ ‡ç®¡ç†
```typescript
class PerformanceMonitor {
    private metrics: Map<string, MetricData> = new Map();
    private startTime: number = Date.now();
    
    recordMetric(name: string, value: number, unit: string = 'ms'): void {
        const metric = this.metrics.get(name) || {
            name,
            values: [],
            unit,
            min: Infinity,
            max: -Infinity,
            sum: 0,
            count: 0
        };
        
        metric.values.push(value);
        metric.min = Math.min(metric.min, value);
        metric.max = Math.max(metric.max, value);
        metric.sum += value;
        metric.count++;
        
        this.metrics.set(name, metric);
    }
    
    getMetricSummary(name: string): MetricSummary | null {
        const metric = this.metrics.get(name);
        if (!metric) return null;
        
        const avg = metric.sum / metric.count;
        const sortedValues = [...metric.values].sort((a, b) => a - b);
        const p50 = sortedValues[Math.floor(sortedValues.length * 0.5)];
        const p95 = sortedValues[Math.floor(sortedValues.length * 0.95)];
        const p99 = sortedValues[Math.floor(sortedValues.length * 0.99)];
        
        return {
            name: metric.name,
            unit: metric.unit,
            count: metric.count,
            min: metric.min,
            max: metric.max,
            avg,
            p50,
            p95,
            p99
        };
    }
    
    getSystemMetrics(): SystemMetrics {
        const memUsage = process.memoryUsage();
        const uptime = Date.now() - this.startTime;
        
        return {
            uptime,
            memory: {
                rss: memUsage.rss,
                heapTotal: memUsage.heapTotal,
                heapUsed: memUsage.heapUsed,
                external: memUsage.external
            },
            cpu: process.cpuUsage()
        };
    }
}
```

### 6.2 å®æ—¶ç›‘æ§

#### æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ
```typescript
class PerformanceReporter {
    private monitor: PerformanceMonitor;
    private reportInterval: number = 60000; // 1åˆ†é’Ÿ
    
    constructor(monitor: PerformanceMonitor) {
        this.monitor = monitor;
        this.startReporting();
    }
    
    private startReporting(): void {
        setInterval(() => {
            this.generateReport();
        }, this.reportInterval);
    }
    
    private generateReport(): void {
        const embeddingMetrics = this.monitor.getMetricSummary('embedding_time');
        const databaseMetrics = this.monitor.getMetricSummary('database_time');
        const systemMetrics = this.monitor.getSystemMetrics();
        
        console.log('ğŸ“Š Performance Report:');
        console.log(`  Uptime: ${this.formatDuration(systemMetrics.uptime)}`);
        console.log(`  Memory Usage: ${this.formatBytes(systemMetrics.memory.heapUsed)} / ${this.formatBytes(systemMetrics.memory.heapTotal)}`);
        
        if (embeddingMetrics) {
            console.log(`  Embedding Time: ${embeddingMetrics.avg.toFixed(2)}ms (p95: ${embeddingMetrics.p95.toFixed(2)}ms)`);
        }
        
        if (databaseMetrics) {
            console.log(`  Database Time: ${databaseMetrics.avg.toFixed(2)}ms (p95: ${databaseMetrics.p95.toFixed(2)}ms)`);
        }
    }
    
    private formatDuration(ms: number): string {
        const seconds = Math.floor(ms / 1000);
        const minutes = Math.floor(seconds / 60);
        const hours = Math.floor(minutes / 60);
        
        if (hours > 0) {
            return `${hours}h ${minutes % 60}m`;
        } else if (minutes > 0) {
            return `${minutes}m ${seconds % 60}s`;
        } else {
            return `${seconds}s`;
        }
    }
    
    private formatBytes(bytes: number): string {
        const sizes = ['Bytes', 'KB', 'MB', 'GB'];
        if (bytes === 0) return '0 Bytes';
        const i = Math.floor(Math.log(bytes) / Math.log(1024));
        return Math.round(bytes / Math.pow(1024, i) * 100) / 100 + ' ' + sizes[i];
    }
}
```

## 7. æ‰©å±•æ€§ç­–ç•¥

### 7.1 æ°´å¹³æ‰©å±•

#### åˆ†ç‰‡ç­–ç•¥
```typescript
class ShardManager {
    private shards: Map<string, Shard> = new Map();
    private hashRing: HashRing;
    
    constructor(shardConfigs: ShardConfig[]) {
        this.hashRing = new HashRing(shardConfigs.map(config => config.id));
        
        for (const config of shardConfigs) {
            this.shards.set(config.id, new Shard(config));
        }
    }
    
    getShardForKey(key: string): Shard {
        const shardId = this.hashRing.getNode(key);
        return this.shards.get(shardId)!;
    }
    
    async distributeOperation<T>(
        operation: (shard: Shard) => Promise<T>,
        key: string
    ): Promise<T> {
        const shard = this.getShardForKey(key);
        return await operation(shard);
    }
    
    async broadcastOperation<T>(
        operation: (shard: Shard) => Promise<T>
    ): Promise<T[]> {
        const promises = Array.from(this.shards.values()).map(
            shard => operation(shard)
        );
        
        return await Promise.all(promises);
    }
}
```

### 7.2 è´Ÿè½½å‡è¡¡

#### åŠ¨æ€è´Ÿè½½åˆ†é…
```typescript
class LoadBalancer {
    private nodes: WorkerNode[];
    private strategy: LoadBalancingStrategy;
    
    constructor(nodes: WorkerNode[], strategy: LoadBalancingStrategy = 'round-robin') {
        this.nodes = nodes;
        this.strategy = strategy;
    }
    
    async getNode(): Promise<WorkerNode> {
        switch (this.strategy) {
            case 'round-robin':
                return this.getRoundRobinNode();
            case 'least-connections':
                return this.getLeastConnectionsNode();
            case 'fastest-response':
                return this.getFastestResponseNode();
            default:
                throw new Error(`Unknown load balancing strategy: ${this.strategy}`);
        }
    }
    
    private getRoundRobinNode(): WorkerNode {
        const node = this.nodes[0];
        this.nodes.push(this.nodes.shift()!);
        return node;
    }
    
    private getLeastConnectionsNode(): WorkerNode {
        return this.nodes.reduce((least, current) => 
            current.getActiveConnections() < least.getActiveConnections() ? current : least
        );
    }
    
    private getFastestResponseNode(): WorkerNode {
        return this.nodes.reduce((fastest, current) => 
            current.getAverageResponseTime() < fastest.getAverageResponseTime() ? current : fastest
        );
    }
}
```

## 8. å®é™…æ€§èƒ½æ•°æ®

### 8.1 åŸºå‡†æµ‹è¯•ç»“æœ

#### ä¸åŒè§„æ¨¡ä»£ç åº“çš„å¤„ç†æ€§èƒ½

| ä»£ç åº“è§„æ¨¡ | æ–‡ä»¶æ•°é‡ | å¤„ç†æ—¶é—´ | å†…å­˜ä½¿ç”¨ | æœç´¢å“åº”æ—¶é—´ |
|-----------|----------|----------|----------|-------------|
| å°å‹ (1Kæ–‡ä»¶) | 1,000 | 2-3åˆ†é’Ÿ | 512MB | 50-100ms |
| ä¸­å‹ (10Kæ–‡ä»¶) | 10,000 | 15-20åˆ†é’Ÿ | 1GB | 100-200ms |
| å¤§å‹ (100Kæ–‡ä»¶) | 100,000 | 2-3å°æ—¶ | 2GB | 200-300ms |
| è¶…å¤§å‹ (1Mæ–‡ä»¶) | 1,000,000 | 20-30å°æ—¶ | 4GB | 300-500ms |

### 8.2 ä¼˜åŒ–æ•ˆæœ

#### æ‰¹é‡å¤„ç†ä¼˜åŒ–å‰åå¯¹æ¯”

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ”¹è¿›å¹…åº¦ |
|------|--------|--------|----------|
| å•æ–‡ä»¶å¤„ç†é€Ÿåº¦ | 10æ–‡ä»¶/ç§’ | 50æ–‡ä»¶/ç§’ | 5x |
| å†…å­˜ä½¿ç”¨å³°å€¼ | 2GB | 512MB | 75% |
| APIè°ƒç”¨æ¬¡æ•° | 1æ¬¡/æ–‡ä»¶ | 1æ¬¡/100æ–‡ä»¶ | 99% |
| é”™è¯¯ç‡ | 5% | 0.5% | 90% |

## 9. æœ€ä½³å®è·µå»ºè®®

### 9.1 é…ç½®ä¼˜åŒ–

#### æ¨èé…ç½®å‚æ•°
```typescript
const recommendedConfigs = {
    smallCodebase: {
        EMBEDDING_BATCH_SIZE: 50,
        CHUNK_LIMIT: 100000,
        MAX_CONCURRENT_EMBEDDINGS: 3,
        MAX_CONCURRENT_DATABASE_OPS: 5
    },
    mediumCodebase: {
        EMBEDDING_BATCH_SIZE: 100,
        CHUNK_LIMIT: 450000,
        MAX_CONCURRENT_EMBEDDINGS: 5,
        MAX_CONCURRENT_DATABASE_OPS: 10
    },
    largeCodebase: {
        EMBEDDING_BATCH_SIZE: 200,
        CHUNK_LIMIT: 1000000,
        MAX_CONCURRENT_EMBEDDINGS: 10,
        MAX_CONCURRENT_DATABASE_OPS: 20
    }
};
```

### 9.2 ç›‘æ§å’Œè°ƒä¼˜

#### æ€§èƒ½ç›‘æ§è¦ç‚¹
- **å†…å­˜ä½¿ç”¨ç›‘æ§**ï¼šé˜²æ­¢å†…å­˜æ³„æ¼å’ŒOOMé”™è¯¯
- **APIå“åº”æ—¶é—´**ï¼šåŠæ—¶å‘ç°å¤–éƒ¨æœåŠ¡æ€§èƒ½é—®é¢˜
- **æ•°æ®åº“è¿æ¥æ•°**ï¼šé¿å…è¿æ¥æ± è€—å°½
- **é”™è¯¯ç‡ç»Ÿè®¡**ï¼šè¯†åˆ«ç³»ç»Ÿæ€§é—®é¢˜
- **ååé‡æŒ‡æ ‡**ï¼šè¯„ä¼°ç³»ç»Ÿå¤„ç†èƒ½åŠ›

#### è°ƒä¼˜ç­–ç•¥
1. **æ¸è¿›å¼è°ƒä¼˜**ï¼šä¸€æ¬¡åªè°ƒæ•´ä¸€ä¸ªå‚æ•°
2. **A/Bæµ‹è¯•**ï¼šå¯¹æ¯”ä¸åŒé…ç½®çš„æ•ˆæœ
3. **åŸºçº¿æµ‹è¯•**ï¼šå»ºç«‹æ€§èƒ½åŸºå‡†ä»¥ä¾¿å¯¹æ¯”
4. **æŒç»­ç›‘æ§**ï¼šé•¿æœŸè·Ÿè¸ªæ€§èƒ½å˜åŒ–è¶‹åŠ¿

## æ€»ç»“

Code Contexté¡¹ç›®é€šè¿‡ä»¥ä¸‹ç­–ç•¥å®ç°äº†é«˜æ€§èƒ½å’Œè‰¯å¥½çš„æ‰©å±•æ€§ï¼š

1. **æ‰¹é‡å¤„ç†**ï¼šä½¿ç”¨ç¼“å†²åŒºå’Œæ‰¹é‡APIè°ƒç”¨ï¼Œæ˜¾è‘—æé«˜å¤„ç†æ•ˆç‡
2. **å†…å­˜ç®¡ç†**ï¼šæµå¼å¤„ç†ã€ä¸»åŠ¨åƒåœ¾å›æ”¶ã€å†…å­˜ç›‘æ§
3. **å¹¶å‘æ§åˆ¶**ï¼šä¿¡å·é‡ã€ä»»åŠ¡é˜Ÿåˆ—ã€è¿æ¥æ± ç®¡ç†
4. **å®¹é”™æœºåˆ¶**ï¼šé‡è¯•ç­–ç•¥ã€é”™è¯¯æ¢å¤ã€ä¼˜é›…é™çº§
5. **ç›‘æ§ä½“ç³»**ï¼šå®æ—¶æ€§èƒ½ç›‘æ§ã€æŒ‡æ ‡æ”¶é›†ã€æŠ¥å‘Šç”Ÿæˆ
6. **æ‰©å±•è®¾è®¡**ï¼šæ°´å¹³æ‰©å±•ã€è´Ÿè½½å‡è¡¡ã€åˆ†å¸ƒå¼å¤„ç†

è¿™äº›ä¼˜åŒ–ç­–ç•¥ä½¿Code Contextèƒ½å¤Ÿé«˜æ•ˆå¤„ç†ä»å‡ åƒåˆ°æ•°ç™¾ä¸‡æ–‡ä»¶è§„æ¨¡çš„ä¸åŒä»£ç åº“ï¼Œä¸ºç”¨æˆ·æä¾›ç¨³å®šã€å¿«é€Ÿçš„ä»£ç æ£€ç´¢æœåŠ¡ã€‚é€šè¿‡åˆç†çš„é…ç½®å’Œç›‘æ§ï¼Œç³»ç»Ÿå¯ä»¥æ ¹æ®ä¸åŒçš„ä½¿ç”¨åœºæ™¯è¿›è¡Œé’ˆå¯¹æ€§ä¼˜åŒ–ï¼Œå®ç°æœ€ä½³çš„æ€§èƒ½è¡¨ç°ã€‚